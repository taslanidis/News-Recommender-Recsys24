{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c586394f",
   "metadata": {},
   "source": [
    "## Using author's libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b82a9797",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scur1565/.conda/envs/transformers4rec_v2_akis/lib/python3.10/site-packages/merlin/dtypes/mappings/tf.py:52: UserWarning: Tensorflow dtype mappings did not load successfully due to an error: No module named 'tensorflow'\n",
      "  warn(f\"Tensorflow dtype mappings did not load successfully due to an error: {exc.msg}\")\n",
      "/home/scur1565/.conda/envs/transformers4rec_v2_akis/lib/python3.10/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'\n",
      "  warn(f\"Triton dtype mappings did not load successfully due to an error: {exc.msg}\")\n",
      "/home/scur1565/.conda/envs/transformers4rec_v2_akis/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from merlin.io import Dataset\n",
    "from nvtabular import ops\n",
    "import nvtabular as nvt\n",
    "from merlin.schema.tags import Tags\n",
    "\n",
    "from merlin.schema import Schema, ColumnSchema, Tags\n",
    "\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import pyarrow as pa\n",
    "\n",
    "from ebrec.utils._constants import (\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    DEFAULT_CLICKED_ARTICLES_COL,\n",
    "    DEFAULT_INVIEW_ARTICLES_COL,\n",
    "    DEFAULT_IMPRESSION_ID_COL,\n",
    "    DEFAULT_SUBTITLE_COL,\n",
    "    DEFAULT_LABELS_COL,\n",
    "    DEFAULT_TITLE_COL,\n",
    "    DEFAULT_USER_COL,\n",
    "    DEFAULT_HISTORY_READ_TIME_COL\n",
    ")\n",
    "\n",
    "\n",
    "from ebrec.utils._behaviors import (\n",
    "    create_binary_labels_column,\n",
    "    sampling_strategy_wu2019,\n",
    "    add_known_user_column,\n",
    "    add_prediction_scores,\n",
    "    truncate_history,\n",
    ")\n",
    "\n",
    "from ebrec.utils._articles import convert_text2encoding_with_transformers\n",
    "from ebrec.utils._polars import concat_str_columns, slice_join_dataframes\n",
    "from ebrec.utils._articles import create_article_id_to_value_mapping\n",
    "from ebrec.utils._nlp import get_transformers_word_embeddings\n",
    "from ebrec.utils._python import write_submission_file, rank_predictions_by_score\n",
    "\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6ce397",
   "metadata": {},
   "source": [
    "## Create Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72e6438d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize an empty schema\n",
    "schema = Schema()\n",
    "\n",
    "article_id_fixed_col = ColumnSchema(\n",
    "    name=\"article_id_fixed\",\n",
    "    dtype=\"int32\",\n",
    "    tags=[Tags.LIST, Tags.CATEGORICAL, Tags.ITEM_ID, Tags.ITEM],\n",
    "    is_list=True,\n",
    "    is_ragged=True,\n",
    ").with_properties({'domain': {'min': 0, 'max': 125541}, 'value_count': {'min': 1, 'max': 500}})\n",
    "\n",
    "read_time_fixed_col = ColumnSchema(\n",
    "    name=\"read_time_fixed\",\n",
    "    dtype=\"float32\",\n",
    "    tags=[Tags.LIST, Tags.CONTINUOUS],\n",
    "    is_list=True,\n",
    "    is_ragged=True\n",
    ")\n",
    "\n",
    "# Add columns to the schema\n",
    "columns = [article_id_fixed_col, read_time_fixed_col]\n",
    "\n",
    "for col in columns:\n",
    "    schema[col.name] = col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2866f93a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>tags</th>\n",
       "      <th>dtype</th>\n",
       "      <th>is_list</th>\n",
       "      <th>is_ragged</th>\n",
       "      <th>properties.value_count.min</th>\n",
       "      <th>properties.value_count.max</th>\n",
       "      <th>properties.domain.min</th>\n",
       "      <th>properties.domain.max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>article_id_fixed</td>\n",
       "      <td>(Tags.ITEM, Tags.ID, Tags.LIST, Tags.CATEGORICAL)</td>\n",
       "      <td>DType(name='int32', element_type=&lt;ElementType....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>125541.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>read_time_fixed</td>\n",
       "      <td>(Tags.CONTINUOUS, Tags.LIST)</td>\n",
       "      <td>DType(name='float32', element_type=&lt;ElementTyp...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "[{'name': 'article_id_fixed', 'tags': {<Tags.ITEM: 'item'>, <Tags.ID: 'id'>, <Tags.LIST: 'list'>, <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'value_count': {'min': 1, 'max': 500}, 'domain': {'min': 0, 'max': 125541}}, 'dtype': DType(name='int32', element_type=<ElementType.Int: 'int'>, element_size=32, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=1, max=500)))), 'is_list': True, 'is_ragged': True}, {'name': 'read_time_fixed', 'tags': {<Tags.CONTINUOUS: 'continuous'>, <Tags.LIST: 'list'>}, 'properties': {'value_count': {'min': 0, 'max': None}}, 'dtype': DType(name='float32', element_type=<ElementType.Float: 'float'>, element_size=32, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=0, max=None)))), 'is_list': True, 'is_ragged': True}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedaaea3",
   "metadata": {},
   "source": [
    "## Load Pre-Trained Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a74e0b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import polars as pl\n",
    "\n",
    "pretrained_embeds_df = pl.read_parquet(\"../data/eb_contrastive_vector/contrastive_vector.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03aa76eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_to_index = {\n",
    "    art_id: num + 1 for num, art_id in enumerate(pretrained_embeds_df['article_id'].to_list())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06832659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "pretrained_embeds = pretrained_embeds_df['contrastive_vector'].to_list()\n",
    "pretrained_embeds = np.vstack([np.zeros(768,)] + [np.array(vec) for vec in pretrained_embeds])\n",
    "\n",
    "pretrained_embeds = torch.from_numpy(pretrained_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81eb8736",
   "metadata": {},
   "outputs": [],
   "source": [
    "split: str = \"large\"\n",
    "history_size: int = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a623addd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers4rec import torch as tr\n",
    "from transformers4rec.torch.ranking_metric import NDCGAt, RecallAt\n",
    "\n",
    "max_sequence_length, d_model = history_size, 64\n",
    "emb_dims = {\"article_id_fixed\": 768}\n",
    "infer_embedding_sizes = True\n",
    "\n",
    "inputs = tr.TabularSequenceFeatures.from_schema(\n",
    "        schema,\n",
    "        max_sequence_length=max_sequence_length,\n",
    "        continuous_projection=d_model,\n",
    "        aggregation=\"concat\",\n",
    "        d_output=100,\n",
    "        masking='causal',\n",
    "        infer_embedding_sizes=infer_embedding_sizes,\n",
    "        embedding_dims=emb_dims\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5aaef6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>tags</th>\n",
       "      <th>dtype</th>\n",
       "      <th>is_list</th>\n",
       "      <th>is_ragged</th>\n",
       "      <th>properties.value_count.min</th>\n",
       "      <th>properties.value_count.max</th>\n",
       "      <th>properties.domain.min</th>\n",
       "      <th>properties.domain.max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>article_id_fixed</td>\n",
       "      <td>(Tags.ITEM, Tags.ID, Tags.LIST, Tags.CATEGORICAL)</td>\n",
       "      <td>DType(name='int32', element_type=&lt;ElementType....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>125541.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>read_time_fixed</td>\n",
       "      <td>(Tags.CONTINUOUS, Tags.LIST)</td>\n",
       "      <td>DType(name='float32', element_type=&lt;ElementTyp...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "[{'name': 'article_id_fixed', 'tags': {<Tags.ITEM: 'item'>, <Tags.ID: 'id'>, <Tags.LIST: 'list'>, <Tags.CATEGORICAL: 'categorical'>}, 'properties': {'value_count': {'min': 1, 'max': 500}, 'domain': {'min': 0, 'max': 125541}}, 'dtype': DType(name='int32', element_type=<ElementType.Int: 'int'>, element_size=32, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=1, max=500)))), 'is_list': True, 'is_ragged': True}, {'name': 'read_time_fixed', 'tags': {<Tags.CONTINUOUS: 'continuous'>, <Tags.LIST: 'list'>}, 'properties': {'value_count': {'min': 0, 'max': None}}, 'dtype': DType(name='float32', element_type=<ElementType.Float: 'float'>, element_size=32, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=0, max=None)))), 'is_list': True, 'is_ragged': True}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6ae1d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabularSequenceFeatures(\n",
       "  (_aggregation): ConcatFeatures()\n",
       "  (to_merge): ModuleDict(\n",
       "    (continuous_module): SequentialBlock(\n",
       "      (0): ContinuousFeatures(\n",
       "        (filter_features): FilterFeatures()\n",
       "        (_aggregation): ConcatFeatures()\n",
       "      )\n",
       "      (1): SequentialBlock(\n",
       "        (0): DenseBlock(\n",
       "          (0): Linear(in_features=1, out_features=64, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (2): AsTabular()\n",
       "    )\n",
       "    (categorical_module): SequenceEmbeddingFeatures(\n",
       "      (filter_features): FilterFeatures()\n",
       "      (embedding_tables): ModuleDict(\n",
       "        (article_id_fixed): Embedding(125542, 768, padding_idx=0)\n",
       "      )\n",
       "    )\n",
       "    (pretrained_embedding_module): PretrainedEmbeddingFeatures(\n",
       "      (filter_features): FilterFeatures()\n",
       "    )\n",
       "  )\n",
       "  (projection_module): SequentialBlock(\n",
       "    (0): DenseBlock(\n",
       "      (0): Linear(in_features=832, out_features=100, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (_masking): CausalLanguageModeling()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr.TabularSequenceFeatures.from_schema(\n",
    "        schema,\n",
    "        max_sequence_length=max_sequence_length,\n",
    "        continuous_projection=d_model,\n",
    "        aggregation=\"concat\",\n",
    "        d_output=100,\n",
    "        masking='causal',\n",
    "        infer_embedding_sizes=True,\n",
    "        embedding_dims={\"article_id_fixed\": 768}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9517349",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    inputs.categorical_module.embedding_tables[\"article_id_fixed\"].weight.copy_(\n",
    "        pretrained_embeds\n",
    "    )\n",
    "\n",
    "inputs.categorical_module.embedding_tables[\"article_id_fixed\"].requires_grad = False\n",
    "inputs.categorical_module.embedding_tables[\n",
    "    \"article_id_fixed\"\n",
    "].weight.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec11414a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Projecting inputs of NextItemPredictionTask to'768' As weight tying requires the input dimension '64' to be equal to the item-id embedding dimension '768'\n"
     ]
    }
   ],
   "source": [
    "# from transformers4rec.torch.ranking_metric import Precision,Recall,Accuracy\n",
    "\n",
    "# Define XLNetConfig class and set default parameters for HF XLNet config  \n",
    "transformer_config = tr.XLNetConfig.build(\n",
    "    d_model=d_model, n_head=4, n_layer=2, total_seq_length=max_sequence_length\n",
    ")\n",
    "# Define the model block including: inputs, masking, projection and transformer block.\n",
    "body = tr.SequentialBlock(\n",
    "    inputs, tr.MLPBlock([64]), tr.TransformerBlock(transformer_config, masking=inputs.masking)\n",
    ")\n",
    "\n",
    "# Define the evaluation top-N metrics and the cut-offs\n",
    "metrics = [NDCGAt(top_ks=[20, 40], labels_onehot=True),  \n",
    "           RecallAt(top_ks=[20, 40], labels_onehot=True)]\n",
    "\n",
    "# Define a head related to next item prediction task \n",
    "head = tr.Head(\n",
    "    body,\n",
    "    tr.NextItemPredictionTask(\n",
    "        weight_tying=True,\n",
    "        metrics=metrics\n",
    "    )\n",
    "    ,inputs=inputs\n",
    ")\n",
    "\n",
    "# Get the end-to-end Model class \n",
    "model = tr.Model(head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0803a8c2",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cff53a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_device_train_batch_size: int = 128\n",
    "per_device_eval_batch_size: int = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea1d1bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers4rec.config.trainer import T4RecTrainingArguments\n",
    "from transformers4rec.torch import Trainer\n",
    "# Set hyperparameters for training \n",
    "train_args = T4RecTrainingArguments(data_loader_engine='merlin', \n",
    "                                    dataloader_drop_last = True,\n",
    "                                    gradient_accumulation_steps = 1,\n",
    "                                    per_device_train_batch_size = per_device_train_batch_size, \n",
    "                                    per_device_eval_batch_size = per_device_eval_batch_size,\n",
    "                                    output_dir = \"./tmp-large\", \n",
    "                                    learning_rate=0.0005,\n",
    "                                    lr_scheduler_type='cosine', \n",
    "                                    learning_rate_num_cosine_cycles_by_epoch=1.5,\n",
    "                                    num_train_epochs=1,\n",
    "                                    max_sequence_length=20, \n",
    "                                    report_to = [],\n",
    "                                    logging_steps=200,\n",
    "                                    save_steps=10000,\n",
    "                                    no_cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be6305f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the T4Rec Trainer, which manages training and evaluation for the PyTorch API\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=train_args,\n",
    "    schema=schema,\n",
    "    compute_metrics=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "caca48c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_paths = f\"/home/scur1565/News-Recommender-Recsys24/data/ebnerd_processed/validation_data_small.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e017fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load('./tmp-large/checkpoint-20000/pytorch_model.bin')\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dce498c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scur1565/.conda/envs/transformers4rec_v2_akis/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3759' max='109375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  3759/109375 04:55 < 2:18:27, 12.71 it/s, Epoch 0.03/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.787100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.741500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.724600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.689100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.690800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>2.670700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>2.661400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>2.629900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>2.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.601800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>2.624000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>2.638900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>2.592300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>2.587500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.560700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>2.564700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>2.585300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>2.519600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain_dataset_or_path \u001b[38;5;241m=\u001b[39m train_paths\n\u001b[1;32m     12\u001b[0m trainer\u001b[38;5;241m.\u001b[39mreset_lr_scheduler()\n\u001b[0;32m---> 13\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m trainer\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFinished training\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/transformers4rec_v2_akis/lib/python3.10/site-packages/transformers/trainer.py:1645\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1640\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m   1642\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1643\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1644\u001b[0m )\n\u001b[0;32m-> 1645\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1646\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1648\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/transformers4rec_v2_akis/lib/python3.10/site-packages/transformers/trainer.py:1943\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1937\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m   1938\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   1940\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1941\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1942\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m-> 1943\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1944\u001b[0m ):\n\u001b[1;32m   1945\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1946\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_paths = [\n",
    "    f\"/home/scur1565/News-Recommender-Recsys24/data/ebnerd_processed/train_data_large_0.parquet\",\n",
    "    f\"/home/scur1565/News-Recommender-Recsys24/data/ebnerd_processed/train_data_large_1.parquet\",\n",
    "    f\"/home/scur1565/News-Recommender-Recsys24/data/ebnerd_processed/train_data_large_2.parquet\",\n",
    "    f\"/home/scur1565/News-Recommender-Recsys24/data/ebnerd_processed/train_data_large_3.parquet\",\n",
    "    f\"/home/scur1565/News-Recommender-Recsys24/data/ebnerd_processed/train_data_large_4.parquet\",\n",
    "    f\"/home/scur1565/News-Recommender-Recsys24/data/ebnerd_processed/train_data_large_5.parquet\",\n",
    "    f\"/home/scur1565/News-Recommender-Recsys24/data/ebnerd_processed/train_data_large_6.parquet\"\n",
    "]\n",
    "\n",
    "trainer.train_dataset_or_path = train_paths\n",
    "trainer.reset_lr_scheduler()\n",
    "trainer.train()\n",
    "trainer.state.global_step += 1\n",
    "print('Finished training')\n",
    "\n",
    "# trainer.eval_dataset_or_path = eval_paths\n",
    "# train_metrics = trainer.evaluate(metric_key_prefix='eval')\n",
    "\n",
    "# for key in sorted(train_metrics.keys()):\n",
    "#     print(\" %s = %s\" % (key, str(train_metrics[key]))) \n",
    "    \n",
    "# from transformers4rec.torch.utils.examples_utils import wipe_memory\n",
    "# wipe_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "010ff7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ebrec.evaluation import MetricEvaluator, AucScore, NdcgScore, MrrScore\n",
    "from typing import List, Tuple\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3db891d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df = pd.read_parquet(f\"/home/scur1565/News-Recommender-Recsys24/data/ebnerd_processed/validation_data_small.parquet\", engine=\"pyarrow\")\n",
    "all_list_ids_inview: List[List[int]] = validation_df[\"article_ids_inview\"].to_list()\n",
    "all_list_ids_clicked: List[List[int]] = validation_df[\"article_ids_clicked\"].to_list()\n",
    "\n",
    "trainer.eval_dataset_or_path = eval_paths\n",
    "dlv = trainer.get_eval_dataloader()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f8ffe7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensure that Validation Dataloader is deterministic: True\n"
     ]
    }
   ],
   "source": [
    "print(f\"Ensure that Validation Dataloader is deterministic: {not dlv.shuffle}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c55cd80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inview_articles_score(\n",
    "    ids_inview: List[int], \n",
    "    ids_clicked: List[int], \n",
    "    prob_list: List[float]\n",
    ") -> List[float]:\n",
    "\n",
    "    inview_scores: List[float] = []\n",
    "    \n",
    "    for inview_id in ids_inview:\n",
    "       inview_scores.append(prob_list[inview_id]) \n",
    "\n",
    "    return inview_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5570dabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7645/7645 [01:07<00:00, 112.50it/s]\n"
     ]
    }
   ],
   "source": [
    "all_inview_scores: List[List[float]] = []\n",
    "index: int = 0\n",
    "# Sample one from data loader\n",
    "for sp_batch in tqdm(dlv):\n",
    "    # pass through body - encoding\n",
    "    body_out = body(sp_batch[0])\n",
    "    # pass encoding through the prediction head\n",
    "    head_out = head(body_out)\n",
    "    # get inview prob scores\n",
    "    head_out = torch.nn.functional.softmax(head_out['next-item'], dim=1)\n",
    "    for list_of_probs in head_out.cpu().detach().numpy():\n",
    "        ids_clicked = all_list_ids_clicked[index]\n",
    "        ids_inview = all_list_ids_inview[index]\n",
    "        inview_scores = get_inview_articles_score(ids_inview, ids_clicked, list_of_probs)\n",
    "\n",
    "        all_inview_scores.append(inview_scores)\n",
    "\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "43d3cf0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MetricEvaluator class>: \n",
       " {\n",
       "    \"auc\": 0.520656605291806,\n",
       "    \"mrr\": 0.3280504726828434,\n",
       "    \"ndcg@5\": 0.36234598039810345,\n",
       "    \"ndcg@10\": 0.44455400704366715\n",
       "}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = MetricEvaluator(\n",
    "    labels=validation_df[\"labels\"].to_list()[:-7],\n",
    "    predictions=all_inview_scores,\n",
    "    metric_functions=[AucScore(), MrrScore(), NdcgScore(k=5), NdcgScore(k=10)],\n",
    ")\n",
    "metrics.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "530dd7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ebrec.utils._python import write_submission_file, rank_predictions_by_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0a4179e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df = validation_df.iloc[0:-7]\n",
    "validation_df['scores'] = all_inview_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "26b8d03b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'with_columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m validation_df \u001b[38;5;241m=\u001b[39m \u001b[43mvalidation_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_columns\u001b[49m(\n\u001b[1;32m      2\u001b[0m     pl\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscores\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;241m.\u001b[39mmap_elements(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mlist\u001b[39m(rank_predictions_by_score(x)))\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mranked_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m validation_df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/transformers4rec_v2_akis/lib/python3.10/site-packages/pandas/core/generic.py:5902\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5895\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   5896\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[1;32m   5897\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[1;32m   5898\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[1;32m   5899\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5900\u001b[0m ):\n\u001b[1;32m   5901\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[0;32m-> 5902\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'with_columns'"
     ]
    }
   ],
   "source": [
    "validation_df = validation_df.with_columns(\n",
    "    pl.col(\"scores\")\n",
    "    .map_elements(lambda x: list(rank_predictions_by_score(x)))\n",
    "    .alias(\"ranked_scores\")\n",
    ")\n",
    "validation_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6230bcde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
