#!/bin/bash

#SBATCH --partition=gpu
#SBATCH --gpus=1
#SBATCH --job-name=trainlargeEXAMPLE
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=18
#SBATCH --time=04:00:00
#SBATCH --output=out/trainlargeEXAMPLE-%A.out


module purge
module load 2023
module load Miniconda3/23.5.2-0
module load CUDA/12.1.1
module load cuDNN/8.9.2.26-CUDA-12.1.1


source activate transformers4rec_v2_akis
pip install scikit-learn

python tr4rec/train.py --split large --history_size 20 --epochs 5 --dataset_type enriched --per_device_train_batch_size 2048 --per_device_eval_batch_size 512

